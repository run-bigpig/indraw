package ai

import (
	"aipic_backend/internal/queue"
	"bytes"
	"context"
	"encoding/binary"
	"fmt"
	"time"

	"cloud.google.com/go/auth/credentials"

	"github.com/zeromicro/go-zero/core/logx"
	"google.golang.org/genai"
)

const (
	ImageModel = "gemini-3-pro-image-preview"
	ChatModel  = "gemini-2.5-flash"
)

// AIConfig AI 服务配置
type AIConfig struct {
	UseVertexAI   bool
	APIKey        string
	Project       string
	Location      string
	Timeout       time.Duration
	MaxConcurrent int
	RetryAttempts int
	RetryDelay    time.Duration
}

// AIClient AI 客户端接口
type AIClient interface {
	GenerateImage(ctx context.Context, req *GenerateImageRequest) (*GenerateImageResponse, error)
	Chat(ctx context.Context, messages []*TextMessage) (*ChatResponse, error)
	Close() error
}

// GenerateImageRequest 生成图像请求
type GenerateImageRequest struct {
	Prompt        string   `json:"prompt"`
	NumImages     int      `json:"num_images"`
	Strength      float64  `json:"strength"`
	Prop          string   `json:"prop"`
	InputImages   [][]byte `json:"input_images,omitempty"`   // 多张输入图像数据（用于图生图融合）
	MaskImage     []byte   `json:"mask_image,omitempty"`     // 遮罩图像数据（用于AI重绘）
	PreserveStyle bool     `json:"preserve_style,omitempty"` // 是否保持风格（用于AI重绘）
	TaskType      string   `json:"task_type"`                // 任务类型：text-to-image, image-to-image, inpaint
}

// GenerateImageResponse 生成图像响应
type GenerateImageResponse struct {
	Images    []GeneratedImage `json:"images"`
	RequestID string           `json:"request_id"`
	Model     string           `json:"model"`
	Usage     *Usage           `json:"usage,omitempty"`
}

// GenerateImageStreamResponse 流式图像生成响应
type GenerateImageStreamResponse struct {
	Text   string           `json:"text,omitempty"`   // 文本内容
	Images []GeneratedImage `json:"images,omitempty"` // 图像内容
	Error  error            `json:"error,omitempty"`  // 错误信息
}

// GeneratedImage 生成的图像
type GeneratedImage struct {
	Data     []byte `json:"data"`
	MimeType string `json:"mime_type"`
	Width    int    `json:"width"`
	Height   int    `json:"height"`
}

// Usage 使用情况统计
type Usage struct {
	InputTokens  int `json:"input_tokens"`
	OutputTokens int `json:"output_tokens"`
	TotalTokens  int `json:"total_tokens"`
}

// ChatResponse 聊天响应
type ChatResponse struct {
	Text      string `json:"text"`            // 生成的文本内容
	RequestID string `json:"request_id"`      // 请求ID
	Model     string `json:"model"`           // 使用的模型名称
	Usage     *Usage `json:"usage,omitempty"` // 使用情况统计
}

// GenAIClient Google GenAI 客户端实现
type GenAIClient struct {
	config AIConfig
	client *genai.Client
}

// NewGenAIClient 创建 Google GenAI 客户端
func NewGenAIClient(config AIConfig) (*GenAIClient, error) {
	if config.APIKey == "" {
		return nil, fmt.Errorf("API key is required")
	}

	ctx := context.Background()
	var client *genai.Client
	var err error

	if config.UseVertexAI {
		if config.Project == "" || config.Location == "" {
			return nil, fmt.Errorf("project and location are required for Vertex AI")
		}
		cre, err := credentials.DetectDefault(&credentials.DetectOptions{
			Scopes:          []string{"https://www.googleapis.com/auth/cloud-platform"},
			CredentialsJSON: []byte(config.APIKey),
		})
		if err != nil {
			return nil, fmt.Errorf("failed to detect credentials: %w", err)
		}
		// 创建 Vertex AI 客户端
		client, err = genai.NewClient(ctx, &genai.ClientConfig{
			Project:     config.Project,
			Location:    config.Location,
			Backend:     genai.BackendVertexAI,
			Credentials: cre,
		})
	} else {
		// 创建 Gemini API 客户端
		client, err = genai.NewClient(ctx, &genai.ClientConfig{
			APIKey:  config.APIKey,
			Backend: genai.BackendGeminiAPI,
		})
	}

	if err != nil {
		return nil, fmt.Errorf("failed to create GenAI client: %w", err)
	}

	genaiClient := &GenAIClient{
		config: config,
		client: client,
	}

	logx.Infof("GenAI client initialized (UseVertexAI: %t)", config.UseVertexAI)
	return genaiClient, nil
}

// GenerateImage 生成图像
func (c *GenAIClient) GenerateImage(ctx context.Context, req *GenerateImageRequest) (*GenerateImageResponse, error) {
	// 验证请求参数
	if err := c.validateRequest(req); err != nil {
		return nil, fmt.Errorf("invalid request: %w", err)
	}

	// 如果客户端未初始化，返回错误
	if c.client == nil {
		return nil, fmt.Errorf("GenAI client not initialized")
	}

	// 使用支持图像生成的模型
	prompt := req.Prompt
	if req.PreserveStyle {
		prompt = fmt.Sprintf("%s, preserve the style of the original image while", req.Prompt)
	}
	// 构建内容部分，根据任务类型添加不同的输入
	parts := []*genai.Part{
		{Text: prompt},
	}

	// 根据任务类型添加图像输入
	switch req.TaskType {
	case queue.MessageTypeImageToImage:
		// 处理多张输入图片，保持顺序
		logx.Infof("Processing %d input images for image-to-image generation", len(req.InputImages))
		for i, imageData := range req.InputImages {
			if len(imageData) > 0 {
				mimeType := c.detectImageMimeType(imageData)
				parts = append(parts, &genai.Part{
					InlineData: &genai.Blob{
						MIMEType:    mimeType,
						Data:        imageData,
						DisplayName: fmt.Sprintf("input_image_%d", i+1),
					},
				})
				logx.Infof("Added input image %d: %s (%d bytes)", i+1, mimeType, len(imageData))
			}
		}
	case queue.MessageTypeInpaint:
		// AI重绘使用第一张图片作为原图
		if len(req.InputImages) > 0 && len(req.InputImages[0]) > 0 {
			parts = append(parts, &genai.Part{
				InlineData: &genai.Blob{
					MIMEType:    c.detectImageMimeType(req.InputImages[0]),
					Data:        req.InputImages[0],
					DisplayName: "original image",
				},
			})
		}
		if len(req.MaskImage) > 0 {
			parts = append(parts, &genai.Part{
				InlineData: &genai.Blob{
					MIMEType:    c.detectImageMimeType(req.MaskImage),
					Data:        req.MaskImage,
					DisplayName: "mask image",
				},
			})
		}
	}

	// 创建内容
	content := &genai.Content{
		Parts: parts,
		Role:  genai.RoleUser,
	}

	logx.Infof("Generating image with model: %s, task_type: %s, prompt: %s, num_images: %d, strength: %.2f",
		ImageModel, req.TaskType, req.Prompt, req.NumImages, req.Strength)

	response, err := c.client.Models.GenerateContent(ctx, ImageModel, []*genai.Content{content}, &genai.GenerateContentConfig{
		Temperature:        c.computeTemperature(req.Strength),
		TopP:               c.computeTopP(req.Strength),
		MaxOutputTokens:    32768,
		ResponseModalities: []string{string(genai.ModalityText), string(genai.ModalityImage)},
	})
	if err != nil {
		return nil, fmt.Errorf("failed to generate content: %w", err)
	}

	// 转换响应格式
	return c.convertContentResponse(response, req)
}

type TextMessage struct {
	Role    string `json:"role"`
	Message string `json:"message"`
}

// Chat 使用 Google Gen AI 进行文本对话
// 该方法接收用户的文本提示，调用 Gemini 模型生成相应的回答内容
// 参数:
//   - ctx: 上下文，用于控制请求的生命周期和超时
//   - prompt: 用户输入的文本提示，不能为空
//
// 返回:
//   - *ChatResponse: 包含生成的文本内容、模型信息和使用统计的响应对象
//   - error: 如果请求失败或参数无效，返回相应的错误信息
func (c *GenAIClient) Chat(ctx context.Context, messages []*TextMessage) (*ChatResponse, error) {
	if len(messages) == 0 {
		return nil, fmt.Errorf("messages is required")
	}
	// 检查客户端是否已初始化
	if c.client == nil {
		return nil, fmt.Errorf("GenAI client not initialized")
	}
	//systemContent
	systemContent := &genai.Content{
		Parts: []*genai.Part{{Text: "You are a professional assistant."}},
		Role:  genai.RoleModel,
	}
	contents := make([]*genai.Content, 0, len(messages))
	for _, message := range messages {
		switch message.Role {
		case "user":
			contents = append(contents, &genai.Content{
				Parts: []*genai.Part{{Text: message.Message}},
				Role:  genai.RoleUser,
			})
		case "assistant":
			contents = append(contents, &genai.Content{
				Parts: []*genai.Part{{Text: message.Message}},
				Role:  genai.RoleModel,
			})
		case "system":
			systemContent.Parts[0].Text = message.Message
		}
	}
	// 调用 GenerateContent API
	response, err := c.client.Models.GenerateContent(ctx, ChatModel, contents, &genai.GenerateContentConfig{
		SystemInstruction: systemContent,
		Temperature:       c.getDefaultTemperature(),
		TopP:              c.getDefaultTopP(),
		MaxOutputTokens:   65535, // 设置最大输出token数
	})

	if err != nil {
		return nil, fmt.Errorf("failed to generate chat response: %w", err)
	}

	// 转换响应为 ChatResponse 格式
	return c.convertChatResponse(response, ChatModel)
}

// validateRequest 验证请求参数
func (c *GenAIClient) validateRequest(req *GenerateImageRequest) error {
	if req.Prompt == "" {
		return fmt.Errorf("prompt is required")
	}

	if len(req.Prompt) > 10000 {
		return fmt.Errorf("prompt too long (max 1000 characters)")
	}

	if req.NumImages < 1 || req.NumImages > 4 {
		return fmt.Errorf("num_images must be between 1 and 4")
	}

	if req.Strength < 0.1 || req.Strength > 1.0 {
		return fmt.Errorf("strength must be between 0.1 and 1.0")
	}

	return nil
}

// computeTemperature 计算温度参数
func (c *GenAIClient) computeTemperature(strength float64) *float32 {
	temp := float32(strength)
	return &temp
}

// computeTopP 计算 top_p 参数
func (c *GenAIClient) computeTopP(strength float64) *float32 {
	tp := float32(0.95)
	return &tp
}

// getDefaultTemperature 获取默认的温度参数，用于聊天场景
func (c *GenAIClient) getDefaultTemperature() *float32 {
	temp := float32(0.7) // 聊天场景使用适中的创造性
	return &temp
}

// getDefaultTopP 获取默认的 top_p 参数，用于聊天场景
func (c *GenAIClient) getDefaultTopP() *float32 {
	tp := float32(0.95) // 聊天场景使用较高的多样性
	return &tp
}

// convertChatResponse 转换 GenAI 响应为聊天响应格式
func (c *GenAIClient) convertChatResponse(response *genai.GenerateContentResponse, modelName string) (*ChatResponse, error) {
	if response == nil || len(response.Candidates) == 0 {
		return nil, fmt.Errorf("no content generated")
	}

	// 获取第一个候选项的文本内容
	candidate := response.Candidates[0]
	if candidate.Content == nil || len(candidate.Content.Parts) == 0 {
		return nil, fmt.Errorf("no content parts found in response")
	}

	var textContent string
	// 遍历所有部分，提取文本内容
	for _, part := range candidate.Content.Parts {
		if part.Text != "" {
			textContent += part.Text
		}
	}

	if textContent == "" {
		return nil, fmt.Errorf("no text content found in response")
	}

	// 构建使用统计信息
	var usage *Usage
	if response.UsageMetadata != nil {
		usage = &Usage{
			InputTokens:  int(response.UsageMetadata.PromptTokenCount),
			OutputTokens: int(response.UsageMetadata.CandidatesTokenCount),
			TotalTokens:  int(response.UsageMetadata.TotalTokenCount),
		}
	}

	return &ChatResponse{
		Text:  textContent,
		Model: modelName,
		Usage: usage,
	}, nil
}

// convertContentResponse 转换 GenAI 内容响应为图像响应格式
func (c *GenAIClient) convertContentResponse(response *genai.GenerateContentResponse, req *GenerateImageRequest) (*GenerateImageResponse, error) {
	if response == nil || len(response.Candidates) == 0 {
		return nil, fmt.Errorf("no content generated")
	}

	var images []GeneratedImage

	// 处理响应中的每个候选项
	for _, candidate := range response.Candidates {
		if candidate.Content == nil || len(candidate.Content.Parts) == 0 {
			continue
		}

		// 遍历每个部分，查找图像数据
		for _, part := range candidate.Content.Parts {
			if part.InlineData != nil {
				// 检查是否是图像数据
				if c.isImageMimeType(part.InlineData.MIMEType) {
					// 从图片数据中解析真实尺寸
					width, height, err := c.getImageDimensions(part.InlineData.Data, part.InlineData.MIMEType)
					if err != nil {
						logx.Errorf("Failed to parse image dimensions: %v", err)
						// 如果解析失败，跳过这张图片
						continue
					}

					image := GeneratedImage{
						Data:     part.InlineData.Data,
						MimeType: part.InlineData.MIMEType,
						Width:    width,
						Height:   height,
					}
					images = append(images, image)
				}
			}
		}
	}

	// 如果没有找到图像数据，返回错误
	if len(images) == 0 {
		return nil, fmt.Errorf("no image data found in API response")
	}

	return &GenerateImageResponse{
		Images: images,
		Model:  "gemini-2.5-flash-image-preview",
		Usage: &Usage{
			InputTokens:  int(response.UsageMetadata.PromptTokenCount),
			OutputTokens: int(response.UsageMetadata.ThoughtsTokenCount),
			TotalTokens:  int(response.UsageMetadata.TotalTokenCount),
		},
	}, nil
}

// isImageMimeType 检查是否是图像 MIME 类型
func (c *GenAIClient) isImageMimeType(mimeType string) bool {
	imageMimeTypes := []string{
		"image/png",
		"image/jpeg",
		"image/jpg",
		"image/webp",
		"image/gif",
	}

	for _, imgType := range imageMimeTypes {
		if mimeType == imgType {
			return true
		}
	}
	return false
}

// getImageDimensions 从图片数据中解析宽高信息
func (c *GenAIClient) getImageDimensions(data []byte, mimeType string) (width, height int, err error) {
	if len(data) == 0 {
		return 0, 0, fmt.Errorf("empty image data")
	}

	switch mimeType {
	case "image/png":
		return c.getPNGDimensions(data)
	case "image/jpeg", "image/jpg":
		return c.getJPEGDimensions(data)
	case "image/webp":
		return c.getWebPDimensions(data)
	case "image/gif":
		return c.getGIFDimensions(data)
	default:
		return 0, 0, fmt.Errorf("unsupported image format: %s", mimeType)
	}
}

// getPNGDimensions 解析PNG图片尺寸
func (c *GenAIClient) getPNGDimensions(data []byte) (width, height int, err error) {
	if len(data) < 24 {
		return 0, 0, fmt.Errorf("invalid PNG data: too short")
	}

	// 检查PNG签名
	pngSignature := []byte{0x89, 0x50, 0x4E, 0x47, 0x0D, 0x0A, 0x1A, 0x0A}
	if !bytes.Equal(data[:8], pngSignature) {
		return 0, 0, fmt.Errorf("invalid PNG signature")
	}

	// 读取IHDR块中的宽高信息（从第16字节开始）
	width = int(binary.BigEndian.Uint32(data[16:20]))
	height = int(binary.BigEndian.Uint32(data[20:24]))

	return width, height, nil
}

// getJPEGDimensions 解析JPEG图片尺寸
func (c *GenAIClient) getJPEGDimensions(data []byte) (width, height int, err error) {
	if len(data) < 4 {
		return 0, 0, fmt.Errorf("invalid JPEG data: too short")
	}

	// 检查JPEG签名
	if data[0] != 0xFF || data[1] != 0xD8 {
		return 0, 0, fmt.Errorf("invalid JPEG signature")
	}

	// 查找SOF0或SOF2标记
	for i := 2; i < len(data)-8; i++ {
		if data[i] == 0xFF && (data[i+1] == 0xC0 || data[i+1] == 0xC2) {
			// SOF标记找到，读取尺寸信息
			if i+7 < len(data) {
				height = int(binary.BigEndian.Uint16(data[i+5 : i+7]))
				width = int(binary.BigEndian.Uint16(data[i+7 : i+9]))
				return width, height, nil
			}
		}
	}

	return 0, 0, fmt.Errorf("could not find JPEG dimensions")
}

// getWebPDimensions 解析WebP图片尺寸
func (c *GenAIClient) getWebPDimensions(data []byte) (width, height int, err error) {
	if len(data) < 30 {
		return 0, 0, fmt.Errorf("invalid WebP data: too short")
	}

	// 检查WebP签名
	if !bytes.Equal(data[0:4], []byte("RIFF")) || !bytes.Equal(data[8:12], []byte("WEBP")) {
		return 0, 0, fmt.Errorf("invalid WebP signature")
	}

	// 检查VP8格式
	if bytes.Equal(data[12:16], []byte("VP8 ")) {
		if len(data) < 30 {
			return 0, 0, fmt.Errorf("invalid VP8 data")
		}
		width = int(binary.LittleEndian.Uint16(data[26:28])) & 0x3fff
		height = int(binary.LittleEndian.Uint16(data[28:30])) & 0x3fff
		return width, height, nil
	}

	// 检查VP8L格式
	if bytes.Equal(data[12:16], []byte("VP8L")) {
		if len(data) < 25 {
			return 0, 0, fmt.Errorf("invalid VP8L data")
		}
		bits := binary.LittleEndian.Uint32(data[21:25])
		width = int(bits&0x3FFF) + 1
		height = int((bits>>14)&0x3FFF) + 1
		return width, height, nil
	}

	return 0, 0, fmt.Errorf("unsupported WebP format")
}

// getGIFDimensions 解析GIF图片尺寸
func (c *GenAIClient) getGIFDimensions(data []byte) (width, height int, err error) {
	if len(data) < 10 {
		return 0, 0, fmt.Errorf("invalid GIF data: too short")
	}

	// 检查GIF签名
	if !bytes.Equal(data[0:3], []byte("GIF")) {
		return 0, 0, fmt.Errorf("invalid GIF signature")
	}

	// 读取宽高信息（小端序）
	width = int(binary.LittleEndian.Uint16(data[6:8]))
	height = int(binary.LittleEndian.Uint16(data[8:10]))

	return width, height, nil
}

// detectImageMimeType 检测图像MIME类型
func (c *GenAIClient) detectImageMimeType(data []byte) string {
	if len(data) < 8 {
		return "image/jpeg" // 默认值
	}

	// PNG签名
	if bytes.Equal(data[:8], []byte{0x89, 0x50, 0x4E, 0x47, 0x0D, 0x0A, 0x1A, 0x0A}) {
		return "image/png"
	}

	// JPEG签名
	if len(data) >= 2 && data[0] == 0xFF && data[1] == 0xD8 {
		return "image/jpeg"
	}

	// WebP签名
	if len(data) >= 12 && bytes.Equal(data[0:4], []byte("RIFF")) && bytes.Equal(data[8:12], []byte("WEBP")) {
		return "image/webp"
	}

	// GIF签名
	if len(data) >= 3 && bytes.Equal(data[0:3], []byte("GIF")) {
		return "image/gif"
	}

	return "image/jpeg" // 默认值
}

// Close 关闭客户端
func (c *GenAIClient) Close() error {
	// Google GenAI Go SDK 的客户端可能不需要显式关闭
	// 或者使用不同的方法名
	logx.Info("GenAI client closed")
	return nil
}

// AIService AI 服务管理器
type AIService struct {
	client    AIClient
	config    AIConfig
	semaphore chan struct{} // 用于控制并发数
}

// NewAIService 创建 AI 服务
func NewAIService(config AIConfig) (*AIService, error) {
	client, err := NewGenAIClient(config)
	if err != nil {
		return nil, fmt.Errorf("failed to create GenAI client: %w", err)
	}

	// 创建信号量来控制并发数
	semaphore := make(chan struct{}, config.MaxConcurrent)

	return &AIService{
		client:    client,
		config:    config,
		semaphore: semaphore,
	}, nil
}

// GenerateImageWithRetry 带重试的图像生成
func (s *AIService) GenerateImageWithRetry(ctx context.Context, req *GenerateImageRequest) (*GenerateImageResponse, error) {
	// 获取信号量，控制并发数
	select {
	case s.semaphore <- struct{}{}:
		defer func() { <-s.semaphore }()
	case <-ctx.Done():
		return nil, ctx.Err()
	}

	var lastErr error
	for attempt := 0; attempt <= s.config.RetryAttempts; attempt++ {
		if attempt > 0 {
			// 等待重试延迟
			select {
			case <-ctx.Done():
				return nil, ctx.Err()
			case <-time.After(s.config.RetryDelay * time.Duration(attempt)):
			}

			logx.Infof("Retrying AI generation (attempt %d/%d)", attempt, s.config.RetryAttempts)
		}

		// 设置超时上下文
		timeoutCtx, cancel := context.WithTimeout(ctx, s.config.Timeout)

		response, err := s.client.GenerateImage(timeoutCtx, req)
		cancel()

		if err == nil {
			return response, nil
		}

		lastErr = err
		logx.Errorf("AI generation attempt %d failed: %v", attempt+1, err)
	}

	return nil, fmt.Errorf("AI generation failed after %d attempts: %w", s.config.RetryAttempts+1, lastErr)
}

// ChatWithRetry 带重试的聊天功能
func (s *AIService) ChatWithRetry(ctx context.Context, messages []*TextMessage) (*ChatResponse, error) {
	// 获取信号量，控制并发数
	select {
	case s.semaphore <- struct{}{}:
		defer func() { <-s.semaphore }()
	case <-ctx.Done():
		return nil, ctx.Err()
	}

	var lastErr error
	for attempt := 0; attempt <= s.config.RetryAttempts; attempt++ {
		if attempt > 0 {
			// 等待重试延迟
			select {
			case <-ctx.Done():
				return nil, ctx.Err()
			case <-time.After(s.config.RetryDelay * time.Duration(attempt)):
			}

			logx.Infof("Retrying AI chat (attempt %d/%d)", attempt, s.config.RetryAttempts)
		}

		// 设置超时上下文
		timeoutCtx, cancel := context.WithTimeout(ctx, s.config.Timeout)

		response, err := s.client.Chat(timeoutCtx, messages)
		cancel()

		if err == nil {
			return response, nil
		}

		lastErr = err
		logx.Errorf("AI chat attempt %d failed: %v", attempt+1, err)
	}

	return nil, fmt.Errorf("AI chat failed after %d attempts: %w", s.config.RetryAttempts+1, lastErr)
}

// GetStats 获取服务统计信息
func (s *AIService) GetStats() map[string]interface{} {
	return map[string]interface{}{
		"use_vertex_ai":   s.config.UseVertexAI,
		"max_concurrent":  s.config.MaxConcurrent,
		"retry_attempts":  s.config.RetryAttempts,
		"timeout":         s.config.Timeout.String(),
		"current_usage":   len(s.semaphore),
		"available_slots": cap(s.semaphore) - len(s.semaphore),
	}
}

// Close 关闭服务
func (s *AIService) Close() error {
	if s.client != nil {
		return s.client.Close()
	}
	return nil
}
